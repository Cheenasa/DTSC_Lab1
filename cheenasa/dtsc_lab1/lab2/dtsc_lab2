{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cheenasa/DTSC_Lab1/blob/main/cheenasa/dtsc_lab1/lab2/dtsc_lab2\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5494c0e8",
      "metadata": {
        "id": "5494c0e8",
        "outputId": "30708868-3906-494b-88df-b8cff63255a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lorem: 1\n",
            "ipsum: 1\n",
            "dolor: 1\n",
            "sit: 2\n",
            "amet: 2\n",
            "consectetur: 1\n",
            "adipiscing: 1\n",
            "elit: 3\n",
            "donec: 1\n",
            "condimentum: 1\n",
            "vel: 1\n",
            "mauris: 1\n",
            "varius: 2\n",
            "id: 1\n",
            "laoreet: 1\n",
            "tortor: 1\n",
            "placerat: 1\n",
            "nulla: 1\n",
            "scelerisque: 1\n",
            "felis: 1\n",
            "ac: 1\n",
            "risus: 1\n",
            "luctus: 1\n",
            "matti: 1\n"
          ]
        }
      ],
      "source": [
        "#Problem 1\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "WORD_RE = re.compile(r\"[\\w']+\")\n",
        "\n",
        "def tokenize(text):\n",
        "    return WORD_RE.findall(text)\n",
        "\n",
        "def map_reduce(filename):\n",
        "    word_counts = defaultdict(int)\n",
        "\n",
        "    with open(filename, 'r') as file:\n",
        "        for line in file:\n",
        "            words = tokenize(line)\n",
        "            for word in words:\n",
        "                word_counts[word.lower()] += 1\n",
        "\n",
        "    return word_counts\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    filename = \"/Users/cheerycheena/Downloads/dtsc701_lab2_prb1.txt\"\n",
        "    word_counts = map_reduce(filename)\n",
        "\n",
        "    # Print the unique words and their counts\n",
        "    for word, count in word_counts.items():\n",
        "        print(f\"{word}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6816f4d1",
      "metadata": {
        "id": "6816f4d1",
        "outputId": "dd364a38-10f5-454f-b2aa-c318c19171b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('this', 1),\n",
              " ('sample', 1),\n",
              " ('input', 1),\n",
              " ('text', 1),\n",
              " ('contains', 1),\n",
              " ('some', 1),\n",
              " ('common', 1),\n",
              " ('words', 1),\n",
              " ('such', 1),\n",
              " ('as', 1),\n",
              " ('these', 1),\n",
              " ('stopwords', 1),\n",
              " ('should', 1),\n",
              " ('be', 1),\n",
              " ('removed', 1),\n",
              " ('output', 1)]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Problem 2\n",
        "\n",
        "import re\n",
        "\n",
        "stop_words = [\"the\", \"and\", \"of\", \"a\", \"to\", \"in\", \"is\", \"it\"]\n",
        "\n",
        "def map_non_stop_words(line):\n",
        "    words = re.sub(r'\\W', ' ', line.lower().strip())\n",
        "    words = words.split()\n",
        "    non_stop_words = [word for word in words if word not in stop_words]\n",
        "    word_count = []\n",
        "    for word in non_stop_words:\n",
        "        word_count.append((word, 1))\n",
        "    return word_count\n",
        "\n",
        "l = \"This is a sample input text. It contains some common words such as the, and, of, a, and to. These stopwords should be removed in the output\"\n",
        "map_non_stop_words(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67d99392",
      "metadata": {
        "id": "67d99392",
        "outputId": "87afd1a1-396c-4be3-99d2-ef46fe6235a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nulla -> Document 3\n",
            "risus -> Document 3\n",
            "consectetur -> Document 1\n",
            "mauris -> Document 2\n",
            "scelerisque -> Document 3\n",
            "varius -> Document 2, Document 3\n",
            "laoreet -> Document 2\n",
            "dolor -> Document 1\n",
            "ipsum -> Document 1\n",
            "condimentum -> Document 2\n",
            "vel -> Document 2\n",
            "placerat -> Document 2\n",
            "luctus -> Document 3\n",
            "amet -> Document 1, Document 3\n",
            "felis -> Document 3\n",
            "donec -> Document 2\n",
            "mattis -> Document 3\n",
            "adipiscing -> Document 1\n",
            "tortor -> Document 2\n",
            "sit -> Document 1, Document 3\n",
            "id -> Document 2\n",
            "lorem -> Document 1\n",
            "ac -> Document 3\n",
            "elit -> Document 1, Document 2, Document 3\n"
          ]
        }
      ],
      "source": [
        "#Problem 3\n",
        "\n",
        "#importing relevant libraries\n",
        "import string #to manipulate string variables and remove punctuation marks.\n",
        "\n",
        "# Define the documents to be inverted\n",
        "document1 = 'Lorem ipsum dolor sit amet, consectetur adipiscing elit.'\n",
        "document2 = 'Donec condimentum elit vel mauris varius, id laoreet tortor placerat.'\n",
        "document3 = 'Nulla scelerisque felis ac risus varius, sit amet luctus elit mattis.'\n",
        "\n",
        "#Remove punctuation marks from the documents\n",
        "for punctuation in string.punctuation:\n",
        "    document1 = document1.replace(punctuation, '')\n",
        "    document2 = document2.replace(punctuation, '')\n",
        "    document3 = document3.replace(punctuation, '')\n",
        "\n",
        "# Convert each document to lowercase and split it into words\n",
        "tokens1 = document1.lower().split()\n",
        "tokens2 = document2.lower().split()\n",
        "tokens3 = document3.lower().split()\n",
        "\n",
        "# Combine the tokens into a list of unique terms\n",
        "words = list(set(tokens1 + tokens2 + tokens3))\n",
        "\n",
        "# Create an empty dictionary to store the inverted index\n",
        "inverted_index = {}\n",
        "\n",
        "# For each term, find the documents that contain it\n",
        "for word in words:\n",
        "    documents = []\n",
        "    if word in tokens1:\n",
        "        documents.append(\"Document 1\")\n",
        "    if word in tokens2:\n",
        "        documents.append(\"Document 2\")\n",
        "    if word in tokens3:\n",
        "        documents.append(\"Document 3\")\n",
        "    inverted_index[word] = documents\n",
        "\n",
        "for word, documents in inverted_index.items():\n",
        "    print(word, \"->\", \", \".join(documents))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3682a53b",
      "metadata": {
        "id": "3682a53b",
        "outputId": "92066508-fc92-48d3-9028-1ef6af415136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a,man: 1\n",
            "man,a: 1\n",
            "a,plan: 2\n",
            "plan,a: 1\n",
            "a,canal: 3\n",
            "canal,panama: 1\n",
            "panama,there: 1\n",
            "there,was: 1\n",
            "was,a: 1\n",
            "plan,to: 1\n",
            "to,build: 1\n",
            "build,a: 1\n",
            "canal,in: 1\n",
            "in,panama: 2\n",
            "panama,in: 1\n",
            "panama,a: 1\n",
            "canal,was: 1\n",
            "was,built: 1\n"
          ]
        }
      ],
      "source": [
        "#Problem 4\n",
        "\n",
        "from collections import Counter\n",
        "from mrjob.job import MRJob\n",
        "import re\n",
        "\n",
        "def map_function(line):\n",
        "  \"\"\"Emits each word bigram as a key-value pair, where the key represents the bigram separated by a comma and the value is set to 1.\"\"\"\n",
        "\n",
        "  words = re.findall(r'\\b\\w+\\b', line.lower())\n",
        "\n",
        "  for i in range(len(words) - 1):\n",
        "    bigram = ','.join(words[i:i+2])\n",
        "    yield bigram, 1\n",
        "\n",
        "def reduce_function(bigram, counts):\n",
        "  \"\"\"Reduces the bigrams by counting their occurrences.\"\"\"\n",
        "\n",
        "  counts[bigram] += 1\n",
        "  return counts\n",
        "\n",
        "def main():\n",
        "  \"\"\"Counts the bigrams in the given text.\"\"\"\n",
        "\n",
        "  text = \"\"\"a man a plan a canal panama there was a plan to build a canal in panama in panama a canal was built.\"\"\"\n",
        "\n",
        "  # Split the text into lines.\n",
        "  lines = text.split('\\n')\n",
        "\n",
        "  # Create a Counter object to store the bigram counts.\n",
        "  counts = Counter()\n",
        "\n",
        "  # Map the lines to bigrams.\n",
        "  for line in lines:\n",
        "    for bigram, count in map_function(line):\n",
        "      counts = reduce_function(bigram, counts)\n",
        "\n",
        "  # Print the bigram counts.\n",
        "  for bigram, count in counts.items():\n",
        "    print(f'{bigram}: {count}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}